{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f33e22141c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w0 = 0.125\n",
    "b0 = 5.\n",
    "x_range = [-20, 60]\n",
    "\n",
    "def load_dataset(n=150, n_tst=150):\n",
    "    np.random.seed(43)\n",
    "\n",
    "    def s(x):\n",
    "        g = (x - x_range[0]) / (x_range[1] - x_range[0])\n",
    "        return 3 * (0.25 + g**2.)\n",
    "\n",
    "    x = (x_range[1] - x_range[0]) * np.random.rand(n) + x_range[0]\n",
    "    eps = np.random.randn(n) * s(x)\n",
    "    y = (w0 * x * (1. + np.sin(x)) + b0) + eps\n",
    "    y = (y - y.mean()) / y.std()\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    return y[:, None], x[:, None]\n",
    "\n",
    "y, x = load_dataset()\n",
    "\n",
    "\n",
    "X = torch.tensor(x, dtype=torch.float)\n",
    "Y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearVariational(nn.Module):\n",
    "    \"\"\"\n",
    "    Mean field approximation of nn.Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, parent, n_batches, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.include_bias = bias        \n",
    "        self.parent = parent\n",
    "        self.n_batches = n_batches\n",
    "        \n",
    "        if getattr(parent, 'accumulated_kl_div', None) is None:\n",
    "            parent.accumulated_kl_div = 0\n",
    "            \n",
    "        # Initialize the variational parameters.\n",
    "        # 𝑄(𝑤)=N(𝜇_𝜃,𝜎2_𝜃)\n",
    "        # Do some random initialization with 𝜎=0.001\n",
    "        self.w_mu = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=0, std=0.001)\n",
    "        )\n",
    "        # proxy for variance\n",
    "        # log(1 + exp(ρ))◦ eps\n",
    "        self.w_p = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=-2.5, std=0.001)\n",
    "        )\n",
    "        if self.include_bias:\n",
    "            self.b_mu = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "            # proxy for variance\n",
    "            self.b_p = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "        \n",
    "    def reparameterize(self, mu, p):\n",
    "        sigma = torch.log(1 + torch.exp(p)) \n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + (eps * sigma)\n",
    "    \n",
    "    def kl_divergence(self, z, mu_theta, p_theta, prior_sd=1):\n",
    "        log_prior = dist.Normal(0, prior_sd).log_prob(z) \n",
    "        log_p_q = dist.Normal(mu_theta, torch.log(1 + torch.exp(p_theta))).log_prob(z) \n",
    "        return (log_p_q - log_prior).sum() / self.n_batches\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.reparameterize(self.w_mu, self.w_p)\n",
    "        \n",
    "        if self.include_bias:\n",
    "            b = self.reparameterize(self.b_mu, self.b_p)\n",
    "        else:\n",
    "            b = 0\n",
    "            \n",
    "        z = x @ w + b\n",
    "        \n",
    "        self.parent.accumulated_kl_div += self.kl_divergence(w, \n",
    "                                                             self.w_mu,\n",
    "                                                             self.w_p, \n",
    "                                                             )\n",
    "        if self.include_bias:\n",
    "            self.parent.accumulated_kl_div += self.kl_divergence(b, \n",
    "                                                                 self.b_mu, \n",
    "                                                                 self.b_p,\n",
    "                                                                 )\n",
    "        return z\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KL:\n",
    "    accumulated_kl_div = 0\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_batches):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            LinearVariational(in_size, hidden_size, self.kl_loss, n_batches),\n",
    "            nn.ReLU(),\n",
    "            LinearVariational(hidden_size, hidden_size, self.kl_loss, n_batches),\n",
    "            nn.ReLU(),\n",
    "            LinearVariational(hidden_size, out_size, self.kl_loss, n_batches)\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/marco/repos/pdl/Bayes_by_backprop.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000004?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000004?line=13'>14</a>\u001b[0m     optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000004?line=14'>15</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m m(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000004?line=15'>16</a>\u001b[0m     loss \u001b[39m=\u001b[39m det_loss(y_pred, Y, m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000004?line=16'>17</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/marco/repos/pdl/Bayes_by_backprop.ipynb Cell 4'\u001b[0m in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000003?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000003?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/marco/miniconda3/envs/pdl/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/marco/repos/pdl/Bayes_by_backprop.ipynb Cell 3'\u001b[0m in \u001b[0;36mLinearVariational.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=51'>52</a>\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=53'>54</a>\u001b[0m z \u001b[39m=\u001b[39m x \u001b[39m@\u001b[39m w \u001b[39m+\u001b[39m b\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39maccumulated_kl_div \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkl_divergence(w, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=56'>57</a>\u001b[0m                                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw_mu,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=57'>58</a>\u001b[0m                                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw_p, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=58'>59</a>\u001b[0m                                                      )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=60'>61</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39maccumulated_kl_div \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkl_divergence(b, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=61'>62</a>\u001b[0m                                                          \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_mu, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=62'>63</a>\u001b[0m                                                          \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_p,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=63'>64</a>\u001b[0m                                                          )\n",
      "\u001b[1;32m/home/marco/repos/pdl/Bayes_by_backprop.ipynb Cell 3'\u001b[0m in \u001b[0;36mLinearVariational.kl_divergence\u001b[0;34m(self, z, mu_theta, p_theta, prior_sd)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkl_divergence\u001b[39m(\u001b[39mself\u001b[39m, z, mu_theta, p_theta, prior_sd\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=41'>42</a>\u001b[0m     log_prior \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mNormal(\u001b[39m0\u001b[39m, prior_sd)\u001b[39m.\u001b[39mlog_prob(z) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=42'>43</a>\u001b[0m     log_p_q \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mNormal(mu_theta, torch\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mexp(p_theta)))\u001b[39m.\u001b[39mlog_prob(z) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marco/repos/pdl/Bayes_by_backprop.ipynb#ch0000001?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (log_p_q \u001b[39m-\u001b[39m log_prior)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_batches\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "\n",
    "def det_loss(y, y_pred, model):\n",
    "    batch_size = y.shape[0]\n",
    "    reconstruction_error = -dist.Normal(y_pred, .1).log_prob(y).sum()\n",
    "    kl = model.accumulated_kl_div\n",
    "    model.reset_kl_div()\n",
    "    return reconstruction_error + kl\n",
    "\n",
    "m = Model(1, 20, 1, n_batches=1)\n",
    "optim = torch.optim.Adam(m.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optim.zero_grad()\n",
    "    y_pred = m(X)\n",
    "    loss = det_loss(y_pred, Y, m)\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d4dce9d7226808f190f2bf308d6fa82873ce04af46d0901c689654b9cd5f0c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pdl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
